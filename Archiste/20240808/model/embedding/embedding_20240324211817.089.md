In the context of your question, I believe you are referring to the process of creating vector representations of words or entities, also known as word embeddings or vector embeddings. These embeddings are often used in natural language processing (NLP) and machine learning tasks to represent words or entities in a way that a machine learning model can understand and process.

In the case of the book "Méditation et Métaphysique" by René Descartes, you might want to create vector embeddings for important words or phrases in the text to analyze their meanings, relationships, or to use them as input to a machine learning model.

In asynchronous JavaScript (Async/JS), you can use libraries like `async` or `bluebird` to handle asynchronous operations, including fetching and processing large datasets required for creating vector embeddings.

Here's a high-level overview of how you might create vector embeddings using Async/JS:

1. **Fetch the text data**: You can use JavaScript's built-in `fetch` function or libraries like `axios` or `node-fetch` to retrieve the text data from a local file or a remote URL.

2. **Tokenize the text**: Before creating vector embeddings, you will need to tokenize the text data into individual words or phrases. You can use libraries like `natural` or `compromise` for tokenization.

3. **Preprocess the tokens**: You might need to preprocess the tokens by removing stop words, stemming, or lemmatization. You can use libraries like `natural`, `compromise`, or `fr-min` for these tasks.

4. **Create the vector embeddings**: After preprocessing the tokens, you can create the vector embeddings using a pre-trained model or training your own model using a library like `word2vec`, `GloVe`, or `fastText`.

5. **Store the vector embeddings**: Once you have created the vector embeddings, you can store them in a database or a file for later use.

To summarize, creating vector embeddings using Async/JS involves fetching the text data, tokenizing and preprocessing the text, creating the vector embeddings, and storing them for later use. While your original question mentioned metadata and a prompt model, I assume you are interested in creating vector embeddings for the text data itself, rather than metadata or prompt models.